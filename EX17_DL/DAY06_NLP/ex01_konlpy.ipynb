{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab14abb",
   "metadata": {},
   "source": [
    "#### 【 자연어 처리용 형태소분석 - KoNLPY 】\n",
    "- 한국어 형태소분석기 중 대표적인 패키지\n",
    "- Java로 개발되어서 JDK 설치 필수\n",
    "- 5개의 한국어 형태소분석기 내장 ==> 자체적인 형태소분석기 없음\n",
    "- 5개의 한국어 형태소분석기를 동일한 메서드로 동일한 동작 가능 => 편리함!\n",
    "- Mecab : Window 지원 중단 / Linux 필수\n",
    "\n",
    "    -> 국내 사용자의 필요성으로 다양한 방식의 Windows 사용법 존재\n",
    "    \n",
    "    -> 버전 및 개발환경 구축이 까다로움!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "from konlpy.corpus import kolaw, kobill     ## 텍스트 데이터 관련\n",
    "from konlpy.tag import *                    ## 형태소분석기 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corpus -> 데이터 일부 추출\n",
    "##-> 파일 선택\n",
    "filename = kolaw.fileids()[0]\n",
    "\n",
    "lawData = kolaw.open(filename).read()\n",
    "print(f'lawData====>\\n{lawData[:300]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jpype\n",
    "# import os\n",
    "\n",
    "# jvm_path = r\"C:\\Program Files\\Java\\jdk-25.0.2\\bin\\server\\jvm.dll\"\n",
    "\n",
    "# if not jpype.isJVMStarted():\n",
    "#     jpype.startJVM(\n",
    "#         jvm_path,\n",
    "#         \"-Djava.class.path=\" + os.environ.get(\"CLASSPATH\", \"\"),\n",
    "#         convertStrings=False\n",
    "#     )\n",
    "\n",
    "# print(\"JVM started:\", jpype.isJVMStarted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc828f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------------------------------------------\n",
    "## 형태소 분리 : 의미를 가진 가장 최소 단위를 형태소.토큰\n",
    "## --------------------------------------------------------\n",
    "## [1] Hannanum 분석기\n",
    "##-> 분석기 인스턴스 생성\n",
    "han = Hannanum()\n",
    "\n",
    "##-> 명사만 추출\n",
    "nounList = han.nouns(lawData)\n",
    "print(f'nounList: {nounList[:10]}')\n",
    "\n",
    "##-> 형태소 분리\n",
    "morphList = han.morphs(lawData)\n",
    "print(f'nounmorphListList: {morphList[:10]}')\n",
    "\n",
    "##-> 품사태깅 추출\n",
    "posList = han.pos(lawData)\n",
    "print(f'posList: {posList[:10]}')\n",
    "\n",
    "##-> 상세한 분석\n",
    "analyList = han.analyze(lawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [2] Hannanum 분석기\n",
    "##-> 분석기 인스턴스 생성\n",
    "kkma = Kkma()\n",
    "\n",
    "##-> 명사만 추출\n",
    "nounList = kkma.nouns(lawData)\n",
    "print(f'nounList: {nounList[:10]}')\n",
    "\n",
    "##-> 형태소 분리\n",
    "morphList = kkma.morphs(lawData)\n",
    "print(f'nounmorphListList: {morphList[:10]}')\n",
    "\n",
    "##-> 품사태깅 추출\n",
    "posList = kkma.pos(lawData)\n",
    "print(f'posList: {posList[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b993e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3] Komoran 분석기\n",
    "##-> 분석기 인스턴스 생성\n",
    "komo = Komoran()\n",
    "\n",
    "##-> 명사만 추출\n",
    "nounList = komo.nouns(lawData)\n",
    "print(f'nounList: {nounList[:10]}')\n",
    "\n",
    "##-> 형태소 분리\n",
    "morphList = komo.morphs(lawData)\n",
    "print(f'nounmorphListList: {morphList[:10]}')\n",
    "\n",
    "##-> 품사태깅 추출\n",
    "posList = komo.pos(lawData)\n",
    "print(f'posList: {posList[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [4] Okt 분석기\n",
    "##-> 분석기 인스턴스 생성\n",
    "okt = Okt()\n",
    "\n",
    "##-> 명사만 추출\n",
    "nounList = okt.nouns(lawData)\n",
    "print(f'nounList: {nounList[:10]}')\n",
    "\n",
    "##-> 형태소 분리\n",
    "morphList = okt.morphs(lawData)\n",
    "print(f'nounmorphListList: {morphList[:10]}')\n",
    "\n",
    "##-> 품사태깅 추출\n",
    "posList = okt.pos(lawData)\n",
    "print(f'posList: {posList[:10]}')\n",
    "\n",
    "##-> 데이터 그대로 추출\n",
    "normList = okt.normalize(lawData)\n",
    "print(f'normList: {normList[:100]}')\n",
    "\n",
    "##-> 파싱/분해 추출\n",
    "phraseList = okt.phrases(lawData)\n",
    "print(f'phraseList: {phraseList[:100]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [5] MeCab 분석기\n",
    "##-> 분석기 인스턴스 생성\n",
    "mecabObj = Mecab()\n",
    "\n",
    "##-> 명사만 추출\n",
    "nounList = mecabObj.nouns(lawData)\n",
    "print(f'nounList: {nounList[:10]}')\n",
    "\n",
    "##-> 형태소 분리\n",
    "morphList = mecabObj.morphs(lawData)\n",
    "print(f'nounmorphListList: {morphList[:10]}')\n",
    "\n",
    "##-> 품사태깅 추출\n",
    "posList = mecabObj.pos(lawData)\n",
    "print(f'posList: {posList[:10]}')\n",
    "\n",
    "##-> 데이터 그대로 추출\n",
    "normList = mecabObj.normalize(lawData)\n",
    "print(f'normList: {normList[:100]}')\n",
    "\n",
    "##-> 파싱/분해 추출\n",
    "phraseList = mecabObj.phrases(lawData)\n",
    "print(f'phraseList: {phraseList[:100]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
