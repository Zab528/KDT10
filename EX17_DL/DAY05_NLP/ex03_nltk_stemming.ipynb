{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f5ae41",
   "metadata": {},
   "source": [
    "#### 【 자연어 처리용 형태소분석 - NLTK 】\n",
    "- 정규화\n",
    "    * 영어 -> 대소문자 일치\n",
    "    * 같은의미 -> 다른 형태 토큰 정리\n",
    "    * 어간추출 : 형태적인 기반으로 어간/어미 분리\n",
    "    * 표제어추출 : 품사기반 문법 활용해서 어간/어미 분리\n",
    "    \n",
    "* nltk.stem 서브모듈 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "from nltk.stem import WordNetLemmatizer                 ## 표제어 추출\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer   ## 어간/어미 추출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c99f2d",
   "metadata": {},
   "source": [
    "[어간/어미 추출] <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf58bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구두점 제거 전 : 253개\n",
      "구두점 제거 후 : 246개\n",
      "불용어 제거 전 : 246개\n",
      "불용어 제거 후 : 134개\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------\n",
    "## [1] 데이터 준비\n",
    "## -------------------------------------------------------\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "## -------------------------------------------------------\n",
    "## [2] 형태적 의미로 어간/어미 분리 => 어근 추출 \n",
    "## -------------------------------------------------------\n",
    "lanStem = LancasterStemmer()\n",
    "portStem = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(f'{word:<16} ---> {lanStem.stem(word)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bf12aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 : 59개\n",
      "['his', 'barber', 'kept', 'his', 'word', '.', 'but', 'keeping', 'such', 'a', 'huge', 'secret', 'to', 'himself', 'was', 'driving', 'him', 'crazy', '.', 'finally', ',', 'the', 'barber', 'went', 'up', 'a', 'mountain', 'and', 'almost', 'to', 'the', 'edge', 'of', 'a', 'cliff', '.', 'he', 'dug', 'a', 'hole', 'in', 'the', 'midst', 'of', 'some', 'reeds', '.', 'he', 'looked', 'about', ',', 'to', 'make', 'sure', 'no', 'one', 'was', 'near', '.']\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------\n",
    "## [2] 텍스트 형태소 분석\n",
    "## -------------------------------------------------------\n",
    "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
    "\n",
    "##- 소문자 형태 일치\n",
    "text = text.lower()\n",
    "\n",
    "##- 형태소 분리 및 저장\n",
    "tk_list = word_tokenize(text)\n",
    "print(f'토큰 : {len(tk_list)}개')\n",
    "print(tk_list)\n",
    "\n",
    "##- 구두점과 불용어 제거\n",
    "# print(f\"구두점과 불용어 제거 전 : {len(tk_list)}\")\n",
    "# puncList = list(punctuation)\n",
    "# swList = stopwords.words(\"english\")\n",
    "\n",
    "# clean_tokens = [\n",
    "#     token for token in tk_list\n",
    "#     if token not in swList and token not in puncList\n",
    "# ]\n",
    "# print(f\"구두점과 불용어 제거 전 : {len(clean_tokens)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4adfadab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['a', 'crazy', 'reeds', 'his', 'no', 'some', 'edge', 'dug', 'one', 'the', 'finally', 'hole', 'near', 'he', 'driving', 'midst', 'went', 'looked', 'secret', ',', 'mountain', 'about', 'almost', 'word', 'of', 'kept', 'but', 'himself', 'make', 'such', 'was', 'up', '.', 'to', 'him', 'keeping', 'huge', 'sure', 'barber', 'and', 'cliff', 'in']\n",
      "25 ['crazy', 'reeds', 'edge', 'dug', 'one', 'finally', 'hole', 'near', 'driving', 'midst', 'went', 'looked', 'secret', ',', 'mountain', 'almost', 'word', 'kept', 'make', '.', 'keeping', 'huge', 'sure', 'barber', 'cliff']\n"
     ]
    }
   ],
   "source": [
    "##- 중복 토큰 제거 진행\n",
    "tk_list = list(set(tk_list))\n",
    "print(len(tk_list), tk_list)\n",
    "\n",
    "##- 불용어 + 구두점 제거\n",
    "allList = swList + puncList\n",
    "for sw in swList:\n",
    "    if sw in tk_list: tk_list.remove(sw)\n",
    "print(len(tk_list), tk_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
