{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f5ae41",
   "metadata": {},
   "source": [
    "#### 【 자연어 처리용 형태소분석 - NLTK 】\n",
    "- 정제 (Cleaning)\n",
    "    * 전처리 과정에서 수시로 발생\n",
    "    * 전처리 시작 전에 미리 수행할 수도 있음\n",
    "    * 토큰화 후 진행 할 수도 있음\n",
    "    * 명식적으로 언제만 한다가 아님!! ==> 필요 시 수시로 진행\n",
    "\n",
    "- 필수 정제 작업\n",
    "    * 구두점 처리\n",
    "    * 문장의 앞 부분/끝 부분 의미 없는 공백\n",
    "    * 주제와 관련 없는 토큰 => 불용어(stopword) 제거\n",
    "        - 공통 불용어 : 언어마다 정해진 것들\n",
    "        - 주제 불용어 : 프로젝트/주제 마다 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2bb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize ##- NLTK 토큰화 함수들\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords       ##- NLTK 영어 불용어 리스트\n",
    "from nltk.tag import pos_tag            ##- NLTK 토큰에 품사 태깅 함수\n",
    "\n",
    "from string import punctuation          ##- 파이썬에서 지정한 구두점 문자열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c99f2d",
   "metadata": {},
   "source": [
    "[토큰화 진행] <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf58bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구두점 제거 전 : 253개\n",
      "구두점 제거 후 : 246개\n",
      "불용어 제거 전 : 246개\n",
      "불용어 제거 후 : 134개\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------\n",
    "## [1] 단어 단위 형태소 분석\n",
    "## -------------------------------------------------------\n",
    "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
    "\n",
    "##- 소문자 형태 일치\n",
    "text = text.lower()\n",
    "\n",
    "## -------------------------------------------------------\n",
    "## [2-1] 구두점 제거\n",
    "## -------------------------------------------------------\n",
    "puncList = list(punctuation)\n",
    "print(f'구두점 제거 전 : {len(text)}개')\n",
    "for pun in puncList:\n",
    "    text=text.replace(pun, \"\")\n",
    "print(f'구두점 제거 후 : {len(text)}개')\n",
    "\n",
    "##- [2-2] 불용어 제거\n",
    "swList = stopwords.words(\"english\")\n",
    "\n",
    "print(f'불용어 제거 전 : {len(text)}개')\n",
    "for sw in swList:\n",
    "    text = text.replace(sw, \"\")\n",
    "print(f'불용어 제거 후 : {len(text)}개')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bf12aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 : 59개\n",
      "['his', 'barber', 'kept', 'his', 'word', '.', 'but', 'keeping', 'such', 'a', 'huge', 'secret', 'to', 'himself', 'was', 'driving', 'him', 'crazy', '.', 'finally', ',', 'the', 'barber', 'went', 'up', 'a', 'mountain', 'and', 'almost', 'to', 'the', 'edge', 'of', 'a', 'cliff', '.', 'he', 'dug', 'a', 'hole', 'in', 'the', 'midst', 'of', 'some', 'reeds', '.', 'he', 'looked', 'about', ',', 'to', 'make', 'sure', 'no', 'one', 'was', 'near', '.']\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------\n",
    "## [2] 텍스트 형태소 분석\n",
    "## -------------------------------------------------------\n",
    "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
    "\n",
    "##- 소문자 형태 일치\n",
    "text = text.lower()\n",
    "\n",
    "##- 형태소 분리 및 저장\n",
    "tk_list = word_tokenize(text)\n",
    "print(f'토큰 : {len(tk_list)}개')\n",
    "print(tk_list)\n",
    "\n",
    "##- 구두점과 불용어 제거\n",
    "# print(f\"구두점과 불용어 제거 전 : {len(tk_list)}\")\n",
    "# puncList = list(punctuation)\n",
    "# swList = stopwords.words(\"english\")\n",
    "\n",
    "# clean_tokens = [\n",
    "#     token for token in tk_list\n",
    "#     if token not in swList and token not in puncList\n",
    "# ]\n",
    "# print(f\"구두점과 불용어 제거 전 : {len(clean_tokens)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4adfadab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['a', 'crazy', 'reeds', 'his', 'no', 'some', 'edge', 'dug', 'one', 'the', 'finally', 'hole', 'near', 'he', 'driving', 'midst', 'went', 'looked', 'secret', ',', 'mountain', 'about', 'almost', 'word', 'of', 'kept', 'but', 'himself', 'make', 'such', 'was', 'up', '.', 'to', 'him', 'keeping', 'huge', 'sure', 'barber', 'and', 'cliff', 'in']\n",
      "25 ['crazy', 'reeds', 'edge', 'dug', 'one', 'finally', 'hole', 'near', 'driving', 'midst', 'went', 'looked', 'secret', ',', 'mountain', 'almost', 'word', 'kept', 'make', '.', 'keeping', 'huge', 'sure', 'barber', 'cliff']\n"
     ]
    }
   ],
   "source": [
    "##- 중복 토큰 제거 진행\n",
    "tk_list = list(set(tk_list))\n",
    "print(len(tk_list), tk_list)\n",
    "\n",
    "##- 불용어 + 구두점 제거\n",
    "allList = swList + puncList\n",
    "for sw in swList:\n",
    "    if sw in tk_list: tk_list.remove(sw)\n",
    "print(len(tk_list), tk_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
