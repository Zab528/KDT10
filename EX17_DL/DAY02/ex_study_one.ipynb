{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6a4a0b",
   "metadata": {},
   "source": [
    "### 【 일변량 데이터기반 회귀 모델 】\n",
    "- 주__제 : 학습 시간에 따른 수능 점수 예측 서비스\n",
    "- 데이터 : study_score_easy.csv\n",
    "- 구__성 : 피쳐(hour) + 타겟(score)\n",
    "- 학__습 : 지도학습 + 회귀\n",
    "- 구__현 : 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9c2e5",
   "metadata": {},
   "source": [
    "[1] 모듈로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ee45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cedd272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1-1] 모듈 로딩\n",
    "import pandas as pd                 # 데이터 분석 및 처리용 모듈\n",
    "import torch                        # 텐서 및 수치, 기본 함수용 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 인공신경망 함수(AF, LF, MF) 관련 모듈\n",
    "import torch.optim as optim         # 경사하강법 알고리즘으로 최적화 관련 모듈\n",
    "\n",
    "from torchinfo import summary       # 모델 구조 확인용 유틸 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15309513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   hours   1000 non-null   float64\n",
      " 1   score   1000 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "## [1-2] 데이터 관련\n",
    "DATA_FILE = '../Data/study_score_easy.csv'\n",
    "\n",
    "##- 데이터 로딩\n",
    "dataDF = pd.read_csv(DATA_FILE)\n",
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd7273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xTS : torch.Size([1000, 1]),  yTS : torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "## [1-3] 데이터 -> Tensor 변환\n",
    "featureDF = dataDF[dataDF.columns[0:1]]\n",
    "xTS       = torch.tensor(featureDF.values, dtype=torch.float32)\n",
    "\n",
    "targetDF = dataDF[dataDF.columns[1:]]\n",
    "yTS      = torch.tensor(targetDF.values)\n",
    "\n",
    "print(f\" xTS : {xTS.shape},  yTS : {yTS.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b0823",
   "metadata": {},
   "source": [
    "[2] ANN 모델 설계 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b571da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------\n",
    "##          입력수         퍼셉트론수/출력수         AF\n",
    "## -------------------------------------------------------------\n",
    "## 입력층       1개                 1개           ★ Pytorch에는\n",
    "##                                               입력층 클래스 X\n",
    "##                                               d입력 텐서를 입력층으로 간주\n",
    "## 은닉층       1개                10개           ReLU\n",
    "## 은닉층      10개                15개           ReLU\n",
    "## 출력층      15개                 1개           -     회귀\n",
    "## -------------------------------------------------------------\n",
    "## 클래스이름 : ScoreModel\n",
    "## 부모클래스 : nn.Module\n",
    "## 오버라이딩 : __init__(self)   : 층 구성 요소 인스턴스 생성\n",
    "##            forward(self, x) : 순전파 진행 메서드\n",
    "##                               x -> 입력층으로 간주!\n",
    "## -------------------------------------------------------------\n",
    "class ScoreModel(nn.Module):\n",
    "    ##- 층 구성 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1_layer=nn.Linear(1, 10)\n",
    "        self.hd2_layer=nn.Linear(10, 15)\n",
    "        self.out_layer=nn.Linear(15, 1)\n",
    "\n",
    "    ##- 순전파 진행 메서드\n",
    "    def forward(self, x):\n",
    "        ## 입력층 -> 은닉층 :  1 -> 10\n",
    "        out = self.hd1_layer(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  10 -> 15\n",
    "        out = self.hd2_layer(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  15 -> 1\n",
    "        ## 회귀모델로 AF 없음!\n",
    "        out = self.out_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266b7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ScoreModel                               --                        --\n",
       "├─Linear: 1-1                            [1, 10]                   20\n",
       "├─Linear: 1-2                            [1, 15]                   165\n",
       "├─Linear: 1-3                            [1, 1]                    16\n",
       "==========================================================================================\n",
       "Total params: 201\n",
       "Trainable params: 201\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 인스턴스 생성\n",
    "model  = ScoreModel()\n",
    "summary(model, input_size=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6531b",
   "metadata": {},
   "source": [
    "[3] 학습 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45bce28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [3-1] 학습 관련 설정값들\n",
    "EPOCHS     = 10                             ## 처음 ~ 끝까지 학습 횟수\n",
    "BATCH_SIZE = 200                            ## 1번 학습할 데이터 크기\n",
    "COUNT      = featureDF.shape[0]/BATCH_SIZE  ## 1에포크에 파라미터 업데이트 횟수\n",
    "COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b742be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3-2] 학습 관련 인스턴스들\n",
    "## -> 모델 인스턴스\n",
    "model = ScoreModel()\n",
    "\n",
    "## -> 손실 계산 인스턴스\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "## -> 최적화 인스턴스\n",
    "adamOpt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b0c78",
   "metadata": {},
   "source": [
    "[4] 학습 진행<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ebba69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m pre_y \u001b[38;5;241m=\u001b[39m model(xTS[sIdx:eIdx])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m##- 손실계산\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myTS\u001b[49m\u001b[43m[\u001b[49m\u001b[43msIdx\u001b[49m\u001b[43m:\u001b[49m\u001b[43meIdx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:3781\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[0;32m   3772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   3773\u001b[0m         mse_loss,\n\u001b[0;32m   3774\u001b[0m         (\u001b[38;5;28minput\u001b[39m, target),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3779\u001b[0m         reduction\u001b[38;5;241m=\u001b[39mreduction,\n\u001b[0;32m   3780\u001b[0m     )\n\u001b[1;32m-> 3781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()):\n\u001b[0;32m   3782\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3783\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   3787\u001b[0m     )\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "## 에포크 당 loss 저장 변수\n",
    "history = []\n",
    "\n",
    "## 학습 진행\n",
    "for idx in range(int(COUNT)):\n",
    "    ##- 배치크기만큼 데이터 추출 인덱스\n",
    "    sIdx = idx  * BATCH_SIZE\n",
    "    eIdx = sIdx + BATCH_SIZE\n",
    "\n",
    "    ##- 배치크기만큼 순전파 진행 ==> 예측값 추출\n",
    "    pre_y = model(xTS[sIdx:eIdx])\n",
    "\n",
    "    ##- 손실계산\n",
    "    print(yTS[sIdx:eIdx])\n",
    "    loss = loss_fn(pre_y, yTS[sIdx:eIdx])\n",
    "\n",
    "    print(loss)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
