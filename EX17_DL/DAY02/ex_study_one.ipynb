{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6a4a0b",
   "metadata": {},
   "source": [
    "### 【 일변량 데이터기반 회귀 모델 】\n",
    "- 주__제 : 학습 시간에 따른 수능 점수 예측 서비스\n",
    "- 데이터 : study_score_easy.csv\n",
    "- 구__성 : 피쳐(hour) + 타겟(score)\n",
    "- 학__습 : 지도학습 + 회귀\n",
    "- 구__현 : 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9c2e5",
   "metadata": {},
   "source": [
    "[1] 모듈로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70ee45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cedd272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1-1] 모듈 로딩\n",
    "import pandas as pd                 # 데이터 분석 및 처리용 모듈\n",
    "import torch                        # 텐서 및 수치, 기본 함수용 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 인공신경망 함수(AF, LF, MF) 관련 모듈\n",
    "import torch.optim as optim         # 경사하강법 알고리즘으로 최적화 관련 모듈\n",
    "\n",
    "from torchinfo import summary       # 모델 구조 확인용 유틸 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15309513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   hours   1000 non-null   float64\n",
      " 1   score   1000 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "## [1-2] 데이터 관련\n",
    "DATA_FILE = '../Data/study_score_easy.csv'\n",
    "\n",
    "##- 데이터 로딩\n",
    "dataDF = pd.read_csv(DATA_FILE)\n",
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fd7273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xTS : torch.Size([1000, 1]),  yTS : torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "## [1-3] 데이터 -> Tensor 변환\n",
    "featureDF = dataDF[dataDF.columns[0:1]]\n",
    "xTS       = torch.tensor(featureDF.values, dtype=torch.float32)\n",
    "\n",
    "targetDF = dataDF[dataDF.columns[1:]]\n",
    "yTS      = torch.tensor(targetDF.values)\n",
    "\n",
    "print(f\" xTS : {xTS.shape},  yTS : {yTS.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b0823",
   "metadata": {},
   "source": [
    "[2] ANN 모델 설계 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b571da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------\n",
    "##          입력수         퍼셉트론수/출력수         AF\n",
    "## -------------------------------------------------------------\n",
    "## 입력층       1개                 1개           ★ Pytorch에는\n",
    "##                                               입력층 클래스 X\n",
    "##                                               d입력 텐서를 입력층으로 간주\n",
    "## 은닉층       1개                10개           ReLU\n",
    "## 은닉층      10개                15개           ReLU\n",
    "## 출력층      15개                 1개           -     회귀\n",
    "## -------------------------------------------------------------\n",
    "## 클래스이름 : ScoreModel\n",
    "## 부모클래스 : nn.Module\n",
    "## 오버라이딩 : __init__(self)   : 층 구성 요소 인스턴스 생성\n",
    "##            forward(self, x) : 순전파 진행 메서드\n",
    "##                               x -> 입력층으로 간주!\n",
    "## -------------------------------------------------------------\n",
    "class ScoreModel(nn.Module):\n",
    "    ##- 층 구성 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1_layer=nn.Linear(1, 10)\n",
    "        self.hd2_layer=nn.Linear(10, 15)\n",
    "        self.out_layer=nn.Linear(15, 1)\n",
    "\n",
    "    ##- 순전파 진행 메서드\n",
    "    def forward(self, x):\n",
    "        ## 입력층 -> 은닉층 :  1 -> 10\n",
    "        out = self.hd1_layer(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  10 -> 15\n",
    "        out = self.hd2_layer(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  15 -> 1\n",
    "        ## 회귀모델로 AF 없음!\n",
    "        out = self.out_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "266b7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ScoreModel                               [1, 1]                    --\n",
       "├─Linear: 1-1                            [1, 10]                   20\n",
       "├─Linear: 1-2                            [1, 15]                   165\n",
       "├─Linear: 1-3                            [1, 1]                    16\n",
       "==========================================================================================\n",
       "Total params: 201\n",
       "Trainable params: 201\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 인스턴스 생성\n",
    "model  = ScoreModel()\n",
    "summary(model, input_size=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6531b",
   "metadata": {},
   "source": [
    "[3] 학습 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45bce28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [3-1] 학습 관련 설정값들\n",
    "EPOCHS     = 10                             ## 처음 ~ 끝까지 학습 횟수\n",
    "BATCH_SIZE = 200                            ## 1번 학습할 데이터 크기\n",
    "COUNT      = featureDF.shape[0]/BATCH_SIZE  ## 1에포크에 파라미터 업데이트 횟수\n",
    "COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b742be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3-2] 학습 관련 인스턴스들\n",
    "## -> 모델 인스턴스\n",
    "model = ScoreModel()\n",
    "\n",
    "## -> 손실 계산 인스턴스\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "## -> 최적화 인스턴스\n",
    "adamOpt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b0c78",
   "metadata": {},
   "source": [
    "[4] 학습 진행<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2ebba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m##- 역전파 + 최적화\u001b[39;00m\n\u001b[0;32m     20\u001b[0m adamOpt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m##<- 역전파: 경사하강법으로 W,b 계산진행\u001b[39;00m\n\u001b[0;32m     22\u001b[0m adamOpt\u001b[38;5;241m.\u001b[39mstep()      \u001b[38;5;66;03m##<- 새로운 W,b 업데이트 진행\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m##- 배치 크기 loss 누적\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "## 에포크 당 loss 저장 변수\n",
    "history = []\n",
    "\n",
    "## 학습 진행\n",
    "for epoch in range(EPOCHS+1):\n",
    "    total_loss = 0\n",
    "    for idx in range(int(COUNT)):\n",
    "        ##- 배치크기만큼 데이터 추출 인덱스\n",
    "        sIdx = idx  * BATCH_SIZE\n",
    "        eIdx = sIdx + BATCH_SIZE\n",
    "\n",
    "        ##- 배치크기만큼 순전파 진행 ==> 예측값 추출\n",
    "        pre_y = model(xTS[sIdx:eIdx])\n",
    "\n",
    "        ##- 손실계산\n",
    "        loss = loss_fn(pre_y, yTS[sIdx:eIdx])\n",
    "        print(pre_y.dtype)\n",
    "        \n",
    "        ##- 역전파 + 최적화\n",
    "        adamOpt.zero_grad()\n",
    "        loss.backward()     ##<- 역전파: 경사하강법으로 W,b 계산진행\n",
    "        adamOpt.step()      ##<- 새로운 W,b 업데이트 진행\n",
    "\n",
    "        ##- 배치 크기 loss 누적\n",
    "        total_loss += loss.item()\n",
    "\n",
    "## 50에포크마다 손실 출력\n",
    "if not epoch%50:\n",
    "    print(f'[{epoch:03}_에포크] loss : {total_loss/COUNT:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
