import gradio as gr
import numpy as np
import torch
import torch.nn as nn
import re
from konlpy.tag import Okt
import util_func as uf

# =====================================================
# âš™ï¸ í™˜ê²½ ì„¤ì •
# =====================================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MAX_LEN = 50

LABEL_NAMES = [
    "ê±´ì¶•í—ˆê°€", "ê²½ì œ", "ê³µí†µ", "êµí†µ", "ë†ì—…ì¶•ì‚°", "ë¬¸í™”ì²´ìœ¡ê´€ê´‘",
    "ë³´ê±´ì†Œ", "ë³µì§€", "ì‚°ë¦¼", "ìƒí•˜ìˆ˜ë„", "ì„¸ë¬´", "ì•ˆì „ê±´ì„¤",
    "ìœ„ìƒ", "ìë™ì°¨", "ì •ë³´í†µì‹ ", "í† ì§€", "í–‰ì •", "í™˜ê²½ë¯¸í™”"
]

# =====================================================
# ğŸ§  ëª¨ë¸ ì •ì˜ (train ë•Œë‘ ë™ì¼í•´ì•¼ í•¨)
# =====================================================
class TextClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        x = self.embedding(x.long())
        _, (h_n, _) = self.lstm(x)
        return self.fc(h_n[-1])

# =====================================================
# ğŸ”¹ ëª¨ë¸ ë¡œë“œ (ğŸ”¥ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
# =====================================================
VOCAB_SIZE = len(uf.word2idx)
NUM_CLASSES = len(LABEL_NAMES)

model = TextClassifier(
    vocab_size=VOCAB_SIZE,
    embed_dim=128,
    hidden_dim=128,
    num_classes=NUM_CLASSES
).to(DEVICE)

model.load_state_dict(
    torch.load("best_text_model.pth", map_location=DEVICE)
)
model.eval()

# =====================================================
# âœ‚ï¸ ì „ì²˜ë¦¬ (train ë•Œì™€ ë™ì¼)
# =====================================================
okt = Okt()
stopwords = ['í•©ë‹ˆë‹¤', 'ë°”ëë‹ˆë‹¤', 'ë¶€íƒ', 'ìš”ì²­', 'ì œë°œ', 'ì£¼ì„¸ìš”', 'í•˜ì‹­ì‹œì˜¤']

def preprocess_text(text):
    text = re.sub('[^ê°€-í£ ]', ' ', text)
    nouns = okt.nouns(text)
    nouns = [w for w in nouns if w not in stopwords and len(w) > 1]
    return ' '.join(nouns)

# =====================================================
# ğŸ”® í…ìŠ¤íŠ¸ Task ë¶„ë¥˜ ëª¨ë¸
# =====================================================
def text_task_model(text):
    if text is None or text.strip() == "":
        return "ì…ë ¥ ì—†ìŒ"

    clean = preprocess_text(text)
    seq = uf.text_to_sequence(clean)
    seq_pad = uf.pad_sequence([seq], max_len=MAX_LEN)

    x = torch.tensor(seq_pad).to(DEVICE)

    with torch.no_grad():
        logits = model(x)
        pred_idx = torch.argmax(logits, dim=1).item()

    return LABEL_NAMES[pred_idx]

# =====================================================
# ğŸ™ï¸ STT / TTS (ë”ë¯¸)
# =====================================================
def stt_func(audio):
    return "ìŒì„± ì¸ì‹ ê²°ê³¼ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤."

def tts_func(text):
    return f"ğŸ”Š {text}"

# =====================================================
# ğŸ“¥ ë¯¼ì› ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# =====================================================
def submit_complaint(image, title, name, phone, content):
    task = text_task_model(content)

    return (
        title,
        name,
        phone,
        content,
        task
    )

# =====================================================
# ğŸ§  Gradio UI
# =====================================================
with gr.Blocks() as demo:

    gr.Markdown("## ğŸ›ï¸ AI ê¸°ë°˜ ë¯¼ì› ì²˜ë¦¬ ì‹œìŠ¤í…œ")

    with gr.Tabs():

        # =========================
        # ë¯¼ì›ì¸ íƒ­
        # =========================
        with gr.Tab("ë¯¼ì›ì¸"):
            with gr.Row():
                with gr.Column(scale=2):
                    image_input = gr.Image(label="ğŸ“· ì‚¬ì§„ ì—…ë¡œë“œ", height=420)

                with gr.Column(scale=3):
                    title_input = gr.Textbox(label="ì œëª©")
                    name_input = gr.Textbox(label="ì„±í•¨")
                    phone_input = gr.Textbox(label="ì „í™”ë²ˆí˜¸")
                    content_input = gr.Textbox(label="ë¯¼ì› ë‚´ìš©", lines=6)
                    audio_input = gr.Audio(source="microphone")
                    stt_btn = gr.Button("ğŸ™ï¸ ìŒì„± â†’ í…ìŠ¤íŠ¸")
                    submit_btn = gr.Button("ğŸ“¨ ë¯¼ì› ì „ì†¡")

        # =========================
        # ìƒë‹´ì¸ íƒ­
        # =========================
        with gr.Tab("ìƒë‹´ì¸"):
            out_title = gr.Textbox(label="ì œëª©", interactive=False)
            out_name = gr.Textbox(label="ì„±í•¨", interactive=False)
            out_phone = gr.Textbox(label="ì „í™”ë²ˆí˜¸", interactive=False)
            out_content = gr.Textbox(label="ë¯¼ì› ë‚´ìš©", interactive=False)
            out_task = gr.Textbox(label="ë¶„ë¥˜ ê²°ê³¼", interactive=False)
            tts_btn = gr.Button("ğŸ”Š ì½ì–´ì£¼ê¸°")
            tts_out = gr.Textbox(label="TTS ì¶œë ¥")

    # ì´ë²¤íŠ¸ ì—°ê²°
    stt_btn.click(stt_func, audio_input, content_input)
    submit_btn.click(
        submit_complaint,
        [image_input, title_input, name_input, phone_input, content_input],
        [out_title, out_name, out_phone, out_content, out_task]
    )
    tts_btn.click(tts_func, out_content, tts_out)

demo.launch()
