{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063c5ffd",
   "metadata": {},
   "source": [
    "## 【 D0120_work_이준기 】\n",
    "### - mnist 손글씨 다중클래스 분류\n",
    "\n",
    "다중 분류 시\n",
    "1. softmax를 직접 사용\n",
    "2. CrossEntropyLoss로 손실 계산 (softmax 자동 적용)\n",
    "\n",
    "-> 두 방법 중 수업 시간에 배운 softmax를 직접 적용해서 학습시키는 방법을 사용해보았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ee78e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1-1] 모듈 로딩\n",
    "import pandas as pd                 # 데이터 분석 및 처리용 모듈\n",
    "import torch                        # 텐서 및 수치, 기본 함수용 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 인공신경망 함수(AF, LF, MF) 관련 모듈\n",
    "import torch.optim as optim         # 경사하강법 알고리즘으로 최적화 관련 모듈\n",
    "\n",
    "from torchinfo import summary       # 모델 구조 확인용 유틸 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b49a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, 5 to 0.617\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "## [1-2] 데이터 관련\n",
    "DATA_FILE = '../Data/mnist_train.csv'\n",
    "\n",
    "##- 데이터 로딩\n",
    "dataDF = pd.read_csv(DATA_FILE)\n",
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "629d32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xTS : torch.Size([10000, 784]),  yTS : torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "## [1-3] 데이터 -> Tensor 변환\n",
    "featureDF = dataDF.iloc[:, 1:]\n",
    "xTS       = torch.tensor(featureDF.values, dtype=torch.float32)\n",
    "\n",
    "targetDF = dataDF.iloc[:, 0]\n",
    "yTS      = torch.tensor(targetDF.values)\n",
    "\n",
    "print(f\" xTS : {xTS.shape},  yTS : {yTS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60388a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------\n",
    "##          입력수         퍼셉트론수/출력수         AF\n",
    "## -------------------------------------------------------------\n",
    "## 입력층       784개             784개           ★ Pytorch에는\n",
    "##                                               입력층 클래스 X\n",
    "##                                               입력 텐서를 입력층으로 간주\n",
    "## 은닉층      784개              128개           ReLU\n",
    "## 은닉층      128개               64개           ReLU\n",
    "## 출력층      64개                10개           -     분류\n",
    "## -------------------------------------------------------------\n",
    "## 클래스이름 : MNISTModel\n",
    "## 부모클래스 : nn.Module\n",
    "## 오버라이딩 : __init__(self)   : 층 구성 요소 인스턴스 생성\n",
    "##            forward(self, x) : 순전파 진행 메서드\n",
    "##                               x -> 입력층으로 간주!\n",
    "## -------------------------------------------------------------\n",
    "class MNISTModel(nn.Module):\n",
    "    ##- 층 구성 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1_layer=nn.Linear(784, 128)\n",
    "        self.hd2_layer=nn.Linear(128, 64)\n",
    "        self.out_layer=nn.Linear(64, 10)\n",
    "\n",
    "    ##- 순전파 진행 메서드\n",
    "    def forward(self, x):\n",
    "        ## 입력층 -> 은닉층 :  784 -> 128\n",
    "        out = self.hd1_layer(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  128 -> 64\n",
    "        out = self.hd2_layer(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        ## 은닉층 -> 은닉층 :  64 -> 10\n",
    "        out = self.out_layer(out)\n",
    "\n",
    "        out = F.log_softmax(out, dim=1) # 다중 뷴류 모델이므로 softmax 활성화 함수 사용\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b2050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNISTModel                               [1, 10]                   --\n",
       "├─Linear: 1-1                            [1, 128]                  100,480\n",
       "├─Linear: 1-2                            [1, 64]                   8,256\n",
       "├─Linear: 1-3                            [1, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 109,386\n",
       "Trainable params: 109,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.44\n",
       "Estimated Total Size (MB): 0.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTModel()\n",
    "summary(model, input_size=(1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7e95da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS     = 1000                           ## 처음 ~ 끝까지 학습 횟수\n",
    "BATCH_SIZE = 200                            ## 1번 학습할 데이터 크기\n",
    "COUNT      = featureDF.shape[0]/BATCH_SIZE  ## 1에포크에 파라미터 업데이트 횟수\n",
    "COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3-2] 학습 관련 인스턴스들\n",
    "## -> 모델 인스턴스\n",
    "model = ScoreModel()\n",
    "\n",
    "## -> 손실 계산 인스턴스\n",
    "loss_fn = nn.NLLLoss()      # softmax 사용 시 사용하는 손실 계산 인스턴스\n",
    "\n",
    "## -> 최적화 인스턴스\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be85f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001_에포크] loss : 0.00000\n",
      "[051_에포크] loss : 0.00000\n",
      "[101_에포크] loss : 0.00000\n",
      "[151_에포크] loss : 0.00000\n",
      "[201_에포크] loss : 0.00000\n",
      "[251_에포크] loss : 0.00000\n",
      "[301_에포크] loss : 0.00000\n",
      "[351_에포크] loss : 0.00006\n",
      "[401_에포크] loss : 0.00001\n",
      "[451_에포크] loss : 0.00000\n",
      "[501_에포크] loss : 0.00000\n",
      "[551_에포크] loss : 0.00000\n",
      "[601_에포크] loss : 0.00000\n",
      "[651_에포크] loss : 0.00000\n",
      "[701_에포크] loss : 0.00000\n",
      "[751_에포크] loss : 0.04865\n",
      "[801_에포크] loss : 0.00008\n",
      "[851_에포크] loss : 0.00001\n",
      "[901_에포크] loss : 0.00000\n",
      "[951_에포크] loss : 0.00000\n"
     ]
    }
   ],
   "source": [
    "## 에포크 당 loss 저장 변수\n",
    "history = []\n",
    "\n",
    "## 학습 진행\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for idx in range(int(COUNT)):\n",
    "        ##- 배치크기만큼 데이터 추출 인덱스\n",
    "        sIdx = idx  * BATCH_SIZE\n",
    "        eIdx = sIdx + BATCH_SIZE\n",
    "\n",
    "        ##- 배치크기만큼 순전파 진행 ==> 예측값 추출+\n",
    "        pre_y = model(xTS[sIdx:eIdx])\n",
    "\n",
    "        ##- 손실계산\n",
    "        loss = loss_fn(pre_y, yTS[sIdx:eIdx])\n",
    "        \n",
    "        ##- 역전파 + 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()     ##<- 역전파: 경사하강법으로 W,b 계산진행\n",
    "        optimizer.step()      ##<- 새로운 W,b 업데이트 진행\n",
    "\n",
    "        ##- 배치 크기 loss 누적\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "\n",
    "    ## 50에포크마다 손실 출력\n",
    "    if not epoch%50:\n",
    "        print(f'[{epoch+1:03}_에포크] loss : {total_loss/COUNT:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
